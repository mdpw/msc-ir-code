{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c405702c-a920-4e44-9d21-15b19e1edad6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ollama\n",
      "  Downloading ollama-0.6.0-py3-none-any.whl.metadata (4.3 kB)\n",
      "Requirement already satisfied: streamlit in e:\\python\\lib\\site-packages (1.32.0)\n",
      "Requirement already satisfied: nest_asyncio in e:\\python\\lib\\site-packages (1.6.0)\n",
      "Collecting pyngrok\n",
      "  Downloading pyngrok-7.4.0-py3-none-any.whl.metadata (8.1 kB)\n",
      "Requirement already satisfied: httpx>=0.27 in e:\\python\\lib\\site-packages (from ollama) (0.28.1)\n",
      "Requirement already satisfied: pydantic>=2.9 in e:\\python\\lib\\site-packages (from ollama) (2.11.7)\n",
      "Requirement already satisfied: altair<6,>=4.0 in e:\\python\\lib\\site-packages (from streamlit) (5.0.1)\n",
      "Requirement already satisfied: blinker<2,>=1.0.0 in e:\\python\\lib\\site-packages (from streamlit) (1.6.2)\n",
      "Requirement already satisfied: cachetools<6,>=4.0 in e:\\python\\lib\\site-packages (from streamlit) (5.3.3)\n",
      "Requirement already satisfied: click<9,>=7.0 in e:\\python\\lib\\site-packages (from streamlit) (8.3.0)\n",
      "Requirement already satisfied: numpy<2,>=1.19.3 in e:\\python\\lib\\site-packages (from streamlit) (1.26.4)\n",
      "Requirement already satisfied: packaging<24,>=16.8 in e:\\python\\lib\\site-packages (from streamlit) (23.2)\n",
      "Requirement already satisfied: pandas<3,>=1.3.0 in e:\\python\\lib\\site-packages (from streamlit) (2.2.2)\n",
      "Requirement already satisfied: pillow<11,>=7.1.0 in e:\\python\\lib\\site-packages (from streamlit) (10.3.0)\n",
      "Requirement already satisfied: protobuf<5,>=3.20 in e:\\python\\lib\\site-packages (from streamlit) (3.20.3)\n",
      "Requirement already satisfied: pyarrow>=7.0 in e:\\python\\lib\\site-packages (from streamlit) (14.0.2)\n",
      "Requirement already satisfied: requests<3,>=2.27 in e:\\python\\lib\\site-packages (from streamlit) (2.32.5)\n",
      "Requirement already satisfied: rich<14,>=10.14.0 in e:\\python\\lib\\site-packages (from streamlit) (13.3.5)\n",
      "Requirement already satisfied: tenacity<9,>=8.1.0 in e:\\python\\lib\\site-packages (from streamlit) (8.2.2)\n",
      "Requirement already satisfied: toml<2,>=0.10.1 in e:\\python\\lib\\site-packages (from streamlit) (0.10.2)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.3.0 in e:\\python\\lib\\site-packages (from streamlit) (4.15.0)\n",
      "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in e:\\python\\lib\\site-packages (from streamlit) (3.1.37)\n",
      "Requirement already satisfied: pydeck<1,>=0.8.0b4 in e:\\python\\lib\\site-packages (from streamlit) (0.8.0)\n",
      "Requirement already satisfied: tornado<7,>=6.0.3 in e:\\python\\lib\\site-packages (from streamlit) (6.4.1)\n",
      "Requirement already satisfied: watchdog>=2.1.5 in e:\\python\\lib\\site-packages (from streamlit) (4.0.1)\n",
      "Requirement already satisfied: PyYAML>=5.1 in e:\\python\\lib\\site-packages (from pyngrok) (6.0.1)\n",
      "Requirement already satisfied: jinja2 in e:\\python\\lib\\site-packages (from altair<6,>=4.0->streamlit) (3.1.4)\n",
      "Requirement already satisfied: jsonschema>=3.0 in e:\\python\\lib\\site-packages (from altair<6,>=4.0->streamlit) (4.19.2)\n",
      "Requirement already satisfied: toolz in e:\\python\\lib\\site-packages (from altair<6,>=4.0->streamlit) (0.12.0)\n",
      "Requirement already satisfied: colorama in e:\\python\\lib\\site-packages (from click<9,>=7.0->streamlit) (0.4.6)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in e:\\python\\lib\\site-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.7)\n",
      "Requirement already satisfied: anyio in e:\\python\\lib\\site-packages (from httpx>=0.27->ollama) (4.2.0)\n",
      "Requirement already satisfied: certifi in e:\\python\\lib\\site-packages (from httpx>=0.27->ollama) (2025.8.3)\n",
      "Requirement already satisfied: httpcore==1.* in e:\\python\\lib\\site-packages (from httpx>=0.27->ollama) (1.0.9)\n",
      "Requirement already satisfied: idna in e:\\python\\lib\\site-packages (from httpx>=0.27->ollama) (3.7)\n",
      "Requirement already satisfied: h11>=0.16 in e:\\python\\lib\\site-packages (from httpcore==1.*->httpx>=0.27->ollama) (0.16.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in e:\\python\\lib\\site-packages (from pandas<3,>=1.3.0->streamlit) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in e:\\python\\lib\\site-packages (from pandas<3,>=1.3.0->streamlit) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in e:\\python\\lib\\site-packages (from pandas<3,>=1.3.0->streamlit) (2023.3)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in e:\\python\\lib\\site-packages (from pydantic>=2.9->ollama) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in e:\\python\\lib\\site-packages (from pydantic>=2.9->ollama) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in e:\\python\\lib\\site-packages (from pydantic>=2.9->ollama) (0.4.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in e:\\python\\lib\\site-packages (from requests<3,>=2.27->streamlit) (2.0.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in e:\\python\\lib\\site-packages (from requests<3,>=2.27->streamlit) (2.2.2)\n",
      "Requirement already satisfied: markdown-it-py<3.0.0,>=2.2.0 in e:\\python\\lib\\site-packages (from rich<14,>=10.14.0->streamlit) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in e:\\python\\lib\\site-packages (from rich<14,>=10.14.0->streamlit) (2.15.1)\n",
      "Requirement already satisfied: smmap<5,>=3.0.1 in e:\\python\\lib\\site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in e:\\python\\lib\\site-packages (from jinja2->altair<6,>=4.0->streamlit) (2.1.3)\n",
      "Requirement already satisfied: attrs>=22.2.0 in e:\\python\\lib\\site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (23.1.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in e:\\python\\lib\\site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (2023.7.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in e:\\python\\lib\\site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.30.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in e:\\python\\lib\\site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.10.6)\n",
      "Requirement already satisfied: mdurl~=0.1 in e:\\python\\lib\\site-packages (from markdown-it-py<3.0.0,>=2.2.0->rich<14,>=10.14.0->streamlit) (0.1.0)\n",
      "Requirement already satisfied: six>=1.5 in e:\\python\\lib\\site-packages (from python-dateutil>=2.8.2->pandas<3,>=1.3.0->streamlit) (1.16.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in e:\\python\\lib\\site-packages (from anyio->httpx>=0.27->ollama) (1.3.0)\n",
      "Downloading ollama-0.6.0-py3-none-any.whl (14 kB)\n",
      "Downloading pyngrok-7.4.0-py3-none-any.whl (25 kB)\n",
      "Installing collected packages: pyngrok, ollama\n",
      "Successfully installed ollama-0.6.0 pyngrok-7.4.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install ollama streamlit nest_asyncio pyngrok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a30534fa-33ee-41d7-be1c-e5ff35fc7e89",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ollama\n",
    "import nest_asyncio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "00eead39-5ac9-40b7-9728-88903befb5ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hey Jupyter kernel, behave nicely if someone tries to start another async loop inside you.\n",
    "# manage clashes of the kernal, when streamlit is running\n",
    "# event loop management\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bfbbd7ae-afa8-4614-a834-c0a0dbdda73d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_customer_email(email: str) -> str:\n",
    "    \"\"\"\n",
    "    Step 1: Analyze and extract key info (intent, order number, sentiment, etc.)\n",
    "    \"\"\"\n",
    "    extract_prompt = f\"\"\"\n",
    "    Analyze the following customer email.\n",
    "    1. Classify the intent (refund request, delivery status, product inquiry, complaint, etc.)\n",
    "    2. Extract key details such as order number, product, sentiment, urgency.\n",
    "    3. Return the result as JSON with keys: intent, order_number, product, sentiment, urgency, summary.\n",
    "\n",
    "    Customer Email:\n",
    "    {email}\n",
    "    \"\"\"\n",
    "    response = ollama.chat(\n",
    "        model=\"phi3:mini\",\n",
    "        messages=[{\"role\": \"user\", \"content\": extract_prompt}]\n",
    "    )\n",
    "    return response['message']['content']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "44d0bda0-26b6-4eaa-8b17-9abbd202f25d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Extracted Understanding:\n",
      " ```json\n",
      "\n",
      "{\n",
      "\n",
      "  \"intent\": \"delivery status inquiry\",\n",
      "\n",
      "  \"order_number\": \"12345\",\n",
      "  \"product\": \"Bluetooth speaker\",\n",
      "\n",
      "  \"sentiment\": \"concerned/anxious\",\n",
      "\n",
      "  \"urgency\": \"high, due to the birthday gift context\"\n",
      "\n",
      "}\n",
      "\n",
      "```\n",
      "\n",
      "Summary: The customer is inquiring about the delivery status of a Bluetooth speaker (Order #12345) that has not yet arrived. They express concern because they intended it as a birthday present and are awaiting an urgent update on its estimated arrival time. \n",
      "\n",
      "‚úâÔ∏è Draft Reply:\n",
      " \n",
      "Dear [Customer's Name],\n",
      "\n",
      "\n",
      "Thank you for reaching out to us regarding your Bluetooth speaker order (Order #12345). We understand how important it is for gifts like yours arrive on time and we apologize for any inconvenience caused by this delay. I have checked our latest tracking information, and as of now, the package was last located in transit with a delivery estimate to be updated within 2-3 hours based on its current location.\n",
      "\n",
      "\n",
      "We appreciate your patience while sorting out these logistical issues quickly for you. As soon as we receive an update from our courier service, I will inform you immediately of the new estimated arrival time or any further actions that might need to be taken to expedite delivery. We value your trust in choosing us and are committed to ensuring a positive experience with every purchase made through our brand.\n",
      "\n",
      "\n",
      "Please accept my sincere apologies for this matter, and thank you again for reaching out directly to Customer Service regarding it. Should there be any additional concerns or if further updates arise before the delivery is confirmed, do not hesitate to contact us at your earliest convenience using [Customer Support Email] or via our customer support hotline.\n",
      "\n",
      "\n",
      "Warm regards,\n",
      "\n",
      "[Your Full Name], Customer Support Team\n",
      "\n",
      "[Company Name]\n"
     ]
    }
   ],
   "source": [
    "def draft_reply(email: str, analysis: str) -> str:\n",
    "    \"\"\"\n",
    "    Step 2: Generate support reply with empathy, professionalism, and business alignment\n",
    "    \"\"\"\n",
    "    business_context = \"\"\"\n",
    "    You are a professional customer support representative at a consumer electronics company. \n",
    "    Always:\n",
    "    - Be polite, empathetic, and concise. \n",
    "    - Acknowledge the customer situation.\n",
    "    - Include relevant details (order info, delivery timing, etc.) when available.\n",
    "    - End positively, reassuring the customer that we value them.\n",
    "    \"\"\"\n",
    "\n",
    "    reply_prompt = f\"\"\"\n",
    "    {business_context}\n",
    "\n",
    "    The customer sent the following email:\n",
    "    {email}\n",
    "\n",
    "    Analysis of their message:\n",
    "    {analysis}\n",
    "\n",
    "    Draft a polite, appropriate email response:\n",
    "    \"\"\"\n",
    "# \"role\": \"user\" means: treat this as if it came from the ‚Äúuser‚Äù in a chat.\n",
    "    response = ollama.chat(\n",
    "        model=\"phi3:mini\",\n",
    "        messages=[{\"role\": \"user\", \"content\": reply_prompt}]\n",
    "    )\n",
    "    return response['message']['content']\n",
    "# =====================================\n",
    "# 4Ô∏è‚É£ Test the pipeline directly (without UI)\n",
    "# =====================================\n",
    "customer_email = \"\"\"\n",
    "Hi Support,\n",
    "I ordered a Bluetooth speaker last week (Order #12345), but it still hasn‚Äôt arrived. \n",
    "Can you please tell me when it will be delivered? I needed it for a birthday gift.\n",
    "\"\"\"\n",
    "\n",
    "analysis = analyze_customer_email(customer_email)\n",
    "reply = draft_reply(customer_email, analysis)\n",
    "\n",
    "print(\"üîç Extracted Understanding:\\n\", analysis, \"\\n\")\n",
    "print(\"‚úâÔ∏è Draft Reply:\\n\", reply)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2efb1fa3-d967-4e62-ba0e-15685633524f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting support_ai_app.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile support_ai_app.py\n",
    "import streamlit as st\n",
    "import ollama\n",
    "\n",
    "def analyze_customer_email(email: str) -> str:\n",
    "    extract_prompt = f\"\"\"\n",
    "    Analyze the following customer email.\n",
    "    1. Classify the intent (refund request, delivery status, product inquiry, complaint, etc.)\n",
    "    2. Extract key details such as order number, product, sentiment, urgency.\n",
    "    3. Return the result as JSON with keys: intent, order_number, product, sentiment, urgency, summary.\n",
    "\n",
    "    Customer Email:\n",
    "    {email}\n",
    "    \"\"\"\n",
    "    response = ollama.chat(\n",
    "        model=\"phi3:mini\",\n",
    "        messages=[{\"role\": \"user\", \"content\": extract_prompt}]\n",
    "    )\n",
    "    return response['message']['content']\n",
    "\n",
    "\n",
    "def draft_reply(email: str, analysis: str) -> str:\n",
    "    business_context = \"\"\"\n",
    "    You are a professional customer support representative at a consumer electronics company.\n",
    "    Always:\n",
    "    - Be polite, empathetic, and concise.\n",
    "    - Acknowledge the customer situation.\n",
    "    - Include relevant details (order info, delivery timing, etc.) when available.\n",
    "    - End positively, reassuring the customer that we value them.\n",
    "    \"\"\"\n",
    "\n",
    "    reply_prompt = f\"\"\"\n",
    "    {business_context}\n",
    "\n",
    "    The customer sent the following email:\n",
    "    {email}\n",
    "\n",
    "    Analysis of their message:\n",
    "    {analysis}\n",
    "\n",
    "    Draft a polite, appropriate email response:\n",
    "    \"\"\"\n",
    "\n",
    "    response = ollama.chat(\n",
    "        model=\"phi3:mini\",\n",
    "        messages=[{\"role\": \"user\", \"content\": reply_prompt}]\n",
    "    )\n",
    "    return response['message']['content']\n",
    "\n",
    "\n",
    "# ------------------ UI -------------------------\n",
    "st.set_page_config(page_title=\"AI Customer Support Assistant\", page_icon=\"üì©\")\n",
    "\n",
    "st.title(\"üì© AI-Powered Customer Support Assistant\")\n",
    "st.write(\"Paste a customer email and let AI analyze and draft a polite, professional reply.\")\n",
    "\n",
    "# Input from user\n",
    "customer_email = st.text_area(\"Customer Email:\", height=200, placeholder=\"Paste the customer email here...\")\n",
    "\n",
    "if st.button(\"Generate Reply\"):\n",
    "    if customer_email.strip():\n",
    "        with st.spinner(\"üîç Analyzing email...\"):\n",
    "            analysis = analyze_customer_email(customer_email)\n",
    "        st.subheader(\"Extracted Understanding\")\n",
    "        st.json(analysis)\n",
    "\n",
    "        with st.spinner(\"‚úçÔ∏è Drafting reply...\"):\n",
    "            reply = draft_reply(customer_email, analysis)\n",
    "\n",
    "        st.subheader(\"AI Drafted Reply\")\n",
    "        st.write(reply)\n",
    "    else:\n",
    "        st.warning(\"Please paste a customer email first.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fa7a3778-ff70-46c4-aa92-04454692b6ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    }
   ],
   "source": [
    "!streamlit run support_ai_app.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7cd7294-9383-43a1-a654-5d5252e54acb",
   "metadata": {},
   "outputs": [],
   "source": [
    "##!streamlit run support_ai_app.py --server.headless true --server.port 8501"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
